{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtjWMEEUMSi1NLO7Pz8Js4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanphiri7/StockMate/blob/main/app.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FlaskApp\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from flask import Flask, jsonify\n",
        "import sqlite3\n",
        "from apscheduler.schedulers.background import BackgroundScheduler\n",
        "import atexit\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "#1 Initialize Database\n",
        "\n",
        "def init_db():\n",
        "    conn = sqlite3.connect('database.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS stocks (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            counter TEXT,\n",
        "            last_price TEXT,\n",
        "            change TEXT,\n",
        "            volume TEXT,\n",
        "            turnover TEXT,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "\n",
        "#2 Scrape Data from MSE\n",
        "\n",
        "def scrape_mse():\n",
        "    url = 'https://www.mse.co.mw/'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        table = soup.find('table')\n",
        "        data = []\n",
        "\n",
        "        if not table:\n",
        "            return []\n",
        "\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:]:\n",
        "            cols = row.find_all('td')\n",
        "            if len(cols) >= 3:\n",
        "                data.append({'Counter': cols[0].text.strip(),\n",
        "                'Last Price (MK)': cols[1].text.strip(),\n",
        "                '% Change': cols[2].text.strip(),\n",
        "                'Volume': cols[3].text.strip(),\n",
        "                'Turnover (MK)': cols[4].text.strip()})\n",
        "\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(\"Scrapping Error:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "#3 Save to SqLite\n",
        "\n",
        "def save_data(stock_data):\n",
        "    conn = sqlite3.connect('database.db')\n",
        "    c = conn.cursor()\n",
        "    for item in stock_data:\n",
        "        # Check for recent duplicate (same counter and price in the last hour)\n",
        "        c.execute('''\n",
        "            SELECT 1 FROM stocks\n",
        "            WHERE counter = ? AND last_price = ? AND change = ? AND volume = ? AND turnover = ?\n",
        "            AND timestamp >= datetime('now', '-1 hour')\n",
        "        ''', (item['Counter'], item['Last Price (MK)'], item['% Change'], item['Volume'], item['Turnover (MK)']))\n",
        "\n",
        "        if not c.fetchone():\n",
        "            c.execute('''\n",
        "                INSERT INTO stocks (counter, last_price, change, volume, turnover)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (item['Counter'], item['Last Price (MK)'], item['% Change'], item['Volume'], item['Turnover (MK)']))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "\n",
        "#4 API Routes\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"StockMate API is running!\"\n",
        "\n",
        "@app.route('/scrape', methods=['GET'])\n",
        "def scrape_and_save():\n",
        "    data = scrape_mse()\n",
        "    if data:\n",
        "        save_data(data)\n",
        "        return jsonify({\"message\": \"Data scraped and saved\", \"count\": len(data)})\n",
        "    else:\n",
        "        return jsonify({\"error\": \"Failed to scrape data\"}), 500\n",
        "\n",
        "@app.route('/stocks', methods=['GET'])\n",
        "def get_stocks():\n",
        "    conn = sqlite3.connect('database.db')\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('SELECT counter, last_price, change, volume, turnover, timestamp FROM stocks ORDER BY timestamp DESC LIMIT 20')\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return jsonify([{\"counter\": r[0], \"last_price\": r[1], \"change\": r[2], \"volume\": r[3], \"turnover\": r[4], \"timestamp\": r[5]} for r in rows])\n",
        "\n",
        "@app.route('/latest_prices', methods=['GET'])\n",
        "def latest_prices():\n",
        "    conn = sqlite3.connect('database.db')\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        SELECT counter, last_price, change, volume, turnover, MAX(timestamp)\n",
        "        FROM stocks\n",
        "        GROUP BY counter\n",
        "    ''')\n",
        "    rows = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return jsonify([\n",
        "        {\n",
        "            \"counter\": r[0],\n",
        "            \"last_price\": r[1],\n",
        "            \"change\": r[2],\n",
        "            \"volume\": r[3],\n",
        "            \"turnover\": r[4],\n",
        "            \"timestamp\": r[5]\n",
        "        } for r in rows\n",
        "    ])\n",
        "\n",
        "# Auto-scraping every hour\n",
        "def scheduled_scrape():\n",
        "    print(\"Scheduled scrape running...\")\n",
        "    data = scrape_mse()\n",
        "    if data:\n",
        "        save_data(data)\n",
        "\n",
        "#Run the App ▶️\n",
        "if __name__ == '__main__':\n",
        "    init_db()\n",
        "\n",
        "    #Start the scheduler\n",
        "    scheduler = BackgroundScheduler()\n",
        "    scheduler.add_job(scheduled_scrape, trigger='interval', hours=1)\n",
        "    scheduler.start()\n",
        "\n",
        "    # Ensure scheduler shuts down when Flask stops\n",
        "    atexit.register(lambda: scheduler.shutdown(wait=False))\n",
        "\n",
        "    app.run(host='0.0.0.0', port=5000, debug=True)"
      ],
      "metadata": {
        "id": "S-ZIhCM529zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31f195b-c1ef-4fdb-c0f4-5b92291483f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}